stages:
  preprocess:
    cmd: >
      python process_dataset.py 
      --data_size 100
      --seed 42
      --response_tokens_list 0,5,10,20,30,40,50
    deps:
      - process_dataset.py

  generate_phi_responses:
    cmd: >
      python generate_phi_responses.py
      --data_size 10
      --batch_size 128
      --seed 42
      --output_dir ./data
      --max_length 512
    deps:
      - generate_phi_responses.py

  train_length_predictors:
    foreach:
      - normal
      - preview5
      - preview10
      - preview20
      - preview30
      - preview40
      - preview50
    do:
      cmd: >
        python lenght_prediction.py
        --data_dir data/lmsys_vicuna-13b_${item}_200K
        --model_name google-bert/bert-base-uncased
        --output_dir results/bert_length_predictor_${item}
        --num_epochs 40
        --batch_size 50
        --learning_rate 1e-5
        --weight_decay 0.01
        --warmup_ratio 0.1
        --early_stopping_patience 2
        --seed 42
        --use_wandb
        --wandb_project output-length-prediction
        --do_train
        --do_eval
      deps:
        - lenght_prediction.py
        - models/BasicBert.py

