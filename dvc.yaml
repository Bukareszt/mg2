stages:
  preprocess:
    cmd: >
      python process_dataset.py 
      --data_size 100
      --seed 42
      --response_tokens_list 0
    deps:
      - process_dataset.py
      
  train_embeddings_predictors:
    foreach:
      - 0
      - 1
      - 2
      - 3
      - 4
      - 5
      - 6
      - 7
      - 8
      - 9
      - 10
      - 11
      - 12
      - 13
      - 14
      - 15
      - 16
      - 17
      - 18
    do:
      cmd: >
        python embedings_prediction.py
        --data_dir data/lmsys_vicuna-13b_preview0_100K
        --output_dir results/embeddings_predictor_${item}
        --do_train
        --do_eval
        --use_wandb
        --wandb_project output-length-prediction
        --layer_idx ${item}
        --use_flash_attention

  train_length_predictors:
    foreach:
      - 0
      - 1
      - 2
      - 3
      - 4
      - 5
    do:
      cmd: >
        python lenght_prediction.py
        --data_dir data/lmsys_vicuna-13b_preview${item}_1000K
        --model_name google-bert/bert-base-uncased
        --output_dir results/bert_length_predictor_${item}
        --num_epochs 40
        --batch_size 30
        --learning_rate 1e-5
        --weight_decay 0.01
        --warmup_ratio 0.1
        --early_stopping_patience 2
        --seed 42
        --use_wandb
        --wandb_project output-length-prediction
        --do_train
        --do_eval
        --max_gen_tokens ${item}
      deps:
        - lenght_prediction.py
        - models/BasicBert.py

